{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7ebb2e-9ad4-4ff6-a7cb-d65ad9184fe7",
   "metadata": {},
   "source": [
    "# RAP analysis environmental variable extraction automated\n",
    "\n",
    "#### Need to change location of RAP analysis file output for external use\n",
    "#### WARNING: script takes lengthly period to read all files and compute/read variables (~30 hours for 1000 mesoscale discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff8751-46e1-4c0c-9bc4-2f0aa270b980",
   "metadata": {},
   "source": [
    "# Unit test to determine if input CSV has all necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49b379-cb3a-44b7-8ee0-ee04f446da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_test(df):\n",
    "    '''Test to make sure each MD contain a product id and a label for RAP analysis files and output to output csv'''\n",
    "    if (input_csv[\"SPC PRODUCT ID\"].isnull().sum().all() == 0) & (input_csv[\"WATCH PARAMETER\"].isnull().sum().all() == 0):\n",
    "        print('✅ CSV file contains all necessary data!')\n",
    "    else:\n",
    "        sys.exit('❌ Error. One or more values are missing. Please check csv file to edit/remove any dates with incomplete values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfdf95-ccbf-44fe-9ad1-00c0b5b79320",
   "metadata": {},
   "source": [
    "# Automated unit test to determine if RAP analysis files contains neccessary environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc246c-f332-4d23-a42f-04a1fb415ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rap_variable_test(ds_raw_file, ds_mean_sea, ds_surface, ds_2m, ds_10m, ds_reflect, year, month, day, hour):\n",
    "    '''Test to make due each RAP analysis file has all desired variables'''\n",
    "    if ds_raw_file.get('PWAT_P0_L200_GLC0')[130, 200] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Precipitable Water Not Avalible in Dataset\"\n",
    "    if ds_mean_sea.mslma[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Mean Sea Level Pressure Not Avalible in Dataset\"\n",
    "    if ds_surface.sp[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Surface Pressure Not Avalible in Dataset\"\n",
    "    if ds_surface.cape[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Surface Based CAPE Not Avalible in Dataset\"\n",
    "    if ds_surface.cin[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Surface Based CIN Not Avalible in Dataset\"\n",
    "    if ds_2m.t2m[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 2-m Temperature Not Avalible in Dataset\"\n",
    "    if ds_2m.r2[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 2-m Relative Humidity Not Avalible in Dataset\"\n",
    "    if ds_2m.sh2[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 2-m Specific Humidity Not Avalible in Dataset\"\n",
    "    if ds_10m.u10[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 10-m U-Component Wind Not Avalible in Dataset\"\n",
    "    if ds_10m.v10[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 10-m V-Component Wind Not Avalible in Dataset\"\n",
    "    if ds_raw_file.get('VUCSH_P0_2L103_GLC0')[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 0-6 km U-Component Wind Shear Not Avalible in Dataset\"\n",
    "    if ds_raw_file.get('VVCSH_P0_2L103_GLC0')[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 0-6 km V-Component Wind Shear Not Avalible in Dataset\"\n",
    "    if ds_raw_file.get('HLCY_P0_2L103_GLC0')[0][130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 0-1 km Storm Relative Helicity Not Avalible in Dataset\"\n",
    "    if ds_raw_file.get('HLCY_P0_2L103_GLC0')[1][130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ 0-3 km Storm Relative Helicity Not Avalible in Dataset\"\n",
    "    if ds_reflect.refd[130, 230] == np.nan:\n",
    "        f\"{year}/{month}/{day}_{hour}00 ⚠️ Composite Reflectivity Not Avalible in Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ecedf-0f31-4787-b78a-e368e117c148",
   "metadata": {},
   "source": [
    "# Download RAP analysis files and extract environmental parameters to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdec79-1d1e-4e7e-ab01-b869358ea26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from csv import writer\n",
    "import urllib.request\n",
    "from metpy.units import units\n",
    "from metpy.calc import dewpoint_from_relative_humidity, lcl, wind_speed\n",
    "import sys\n",
    "\n",
    "# Import warnings package to prevent non-critical warnings from displaying\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Read in csv file with mesoscale discussion data\n",
    "input_csv = pd.read_csv(\"central_ok_mds_FINAL.csv\")\n",
    "csv_test(input_csv)\n",
    "\n",
    "prod_id_list = list(input_csv[\"SPC PRODUCT ID\"])\n",
    "csv_watch_md_list = list(input_csv[\"WATCH PARAMETER\"])\n",
    "\n",
    "# Set constants\n",
    "placeholder = -9999\n",
    "input_csv_row = 0\n",
    " \n",
    "for j in prod_id_list:\n",
    "        \n",
    "    # Extract whether watch (1) or md (0) was issued\n",
    "    label = int(csv_watch_md_list[input_csv_row])\n",
    "        \n",
    "    # Create year, month, day, and hour fields based upon the Product ID \n",
    "    year = str(prod_id_list[input_csv_row][0:4])\n",
    "    month = str(prod_id_list[input_csv_row][4:6])\n",
    "    day = str(prod_id_list[input_csv_row][6:8])\n",
    "    hour = str(prod_id_list[input_csv_row][8:10])\n",
    "        \n",
    "    try:\n",
    "        # NCEI 13km RAP Non-Operational Archive (Long-Term)\n",
    "        urllib.request.urlretrieve(f\"https://www.ncei.noaa.gov/thredds/fileServer/model-rap130anl-old/{year}{month}/{year}{month}{day}/rap_130_{year}{month}{day}_{hour}00_000.grb2\", \n",
    "                                       f\"/home/scratch/nsonntag/eae598/rap_data/rap_130_{year}{month}{day}_{hour}00_000.grb2\")\n",
    "        ds_avail_check = 1\n",
    "    except:\n",
    "        try:\n",
    "            # NCEI 13km RAP Operational Archive (Short-Term)\n",
    "            urllib.request.urlretrieve(f\"https://www.ncei.noaa.gov/thredds/fileServer/model-rap130anl/{year}{month}/{year}{month}{day}/rap_130_{year}{month}{day}_{hour}00_000.grb2\", \n",
    "                                           f\"/home/scratch/nsonntag/eae598/rap_data/rap_130_{year}{month}{day}_{hour}00_000.grb2\")\n",
    "            ds_avail_check = 1\n",
    "        except:\n",
    "            # Print Date and Message that Date Isn't Avalible in Archive\n",
    "            ds_avail_check = 0\n",
    "            print(f\"{year}/{month}/{day}_{hour}00 ❌ RAP Analysis File Not Avalible in Dataset\")\n",
    "                \n",
    "    # Check if dataset is available        \n",
    "    if ds_avail_check == 1:\n",
    "            \n",
    "        # Input location of RAP analysis file\n",
    "        ds = f\"/home/scratch/nsonntag/eae598/rap_data/rap_130_{year}{month}{day}_{hour}00_000.grb2\"\n",
    "            \n",
    "        # User defined array of grid points over which variable will be averaged\n",
    "        # can be calc\n",
    "        grid_y = [126, 126, 126, 127, 127, 127, 127, 127, 127, 127, 128, 128, 128, 128, 128, 128, 128, 129, 129, \n",
    "                  129, 129, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130, 130, 130, 130, 131, 131, 131, \n",
    "                  131, 131, 131, 131, 131, 131, 132, 132, 132, 132, 132, 132, 132, 132, 132, 133, 133, 133, 133, \n",
    "                  133, 133, 133, 134, 134, 134, 134, 134]\n",
    "        grid_x = [228, 229, 230, 226, 227, 228, 229, 230, 231, 232, 226, 227, 228, 229, 230, 231, 232, 225, 226, \n",
    "                  227, 228, 229, 230, 231, 232, 233, 225, 226, 227, 228, 229, 230, 231, 232, 233, 225, 226, 227, \n",
    "                  228, 229, 230, 231, 232, 233, 225, 226, 227, 228, 229, 230, 231, 232, 233, 226, 227, 228, 229, \n",
    "                  230, 231, 232, 227, 228, 229, 230, 231]\n",
    "            \n",
    "        grid_points = np.vstack((grid_y, grid_x)).T\n",
    "            \n",
    "        # Open RAP analysis file for each defined level\n",
    "        ds_dbz = xr.open_dataset(ds, filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 1000})\n",
    "        ds_raw = xr.open_dataset(ds, engine=\"pynio\")\n",
    "        ds_ms = xr.open_dataset(ds, filter_by_keys={'typeOfLevel': 'meanSea'})\n",
    "        ds_sfc = xr.open_dataset(ds, filter_by_keys={'stepType': 'instant', 'typeOfLevel': 'surface'})\n",
    "        ds_2 = xr.open_dataset(ds, filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 2})\n",
    "        ds_10 = xr.open_dataset(ds, filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 10})\n",
    "        \n",
    "        # Unit test for environmental variables in RAP analysis data \n",
    "        rap_variable_test(ds_raw, ds_ms, ds_sfc, ds_2, ds_10, ds_dbz, year, month, day, hour)\n",
    "        \n",
    "        # Set sums over user defined grid equal to zero for computation proposes\n",
    "        pwat_sum = mslp_sum = cape_sum = cin_sum = t2m_sum = rh2m_sum = q2m_sum = u10_sum = v10_sum = 0\n",
    "        uv10_sum = lcl_sum = shear_0_6_sum = srh_0_1_sum = srh_0_3_sum = 0\n",
    "        \n",
    "        # set number of points not filtered by reflectivity equal to zero\n",
    "        number_points = 0\n",
    "            \n",
    "        # Run analysis over all user defined grid\n",
    "        for i in range(len(grid_points)):\n",
    "            \n",
    "            # filter out point that have a radar reflectivity greater than 30 dBz\n",
    "            reflectivity = ds_dbz.refd[grid_points[i,0], grid_points[i,1]]\n",
    "            \n",
    "            if reflectivity <= 30:\n",
    "                \n",
    "                # Precipitable water\n",
    "                pwat_point = ds_raw.get('PWAT_P0_L200_GLC0')[grid_points[i,0], grid_points[i,1]]\n",
    "                pwat_sum = pwat_sum + pwat_point\n",
    "                \n",
    "                # Mean sea level pressure\n",
    "                mslp_point = ds_ms.mslma[grid_points[i,0], grid_points[i,1]]\n",
    "                mslp_sum = mslp_sum + mslp_point\n",
    "                \n",
    "                # Surface pressure for bulk shear calculations\n",
    "                slp_point = ds_sfc.sp[grid_points[i,0], grid_points[i,1]]\n",
    "                \n",
    "                # Convective available potential energy\n",
    "                cape_point = ds_sfc.cape[grid_points[i,0], grid_points[i,1]]\n",
    "                cape_sum = cape_sum + cape_point\n",
    "                \n",
    "                # Convective inhibition\n",
    "                cin_point = ds_sfc.cin[grid_points[i,0], grid_points[i,1]]\n",
    "                cin_sum = cin_sum + cin_point\n",
    "                \n",
    "                # 2-m temperature\n",
    "                t2m_point = ds_2.t2m[grid_points[i,0], grid_points[i,1]]\n",
    "                t2m_sum = t2m_sum + t2m_point\n",
    "                \n",
    "                # 2-m relative humidity\n",
    "                rh2m_point = ds_2.r2[grid_points[i,0], grid_points[i,1]]\n",
    "                rh2m_sum = rh2m_sum + rh2m_point\n",
    "                \n",
    "                # 2-m specific humidity\n",
    "                q2m_point = ds_2.sh2[grid_points[i,0], grid_points[i,1]]\n",
    "                q2m_sum = q2m_sum + q2m_point\n",
    "                \n",
    "                # 10-m u-component wind\n",
    "                u10_point = ds_10.u10[grid_points[i,0], grid_points[i,1]]\n",
    "                u10_sum = u10_sum + u10_point\n",
    "                \n",
    "                # 10-m v-component wind\n",
    "                v10_point = ds_10.v10[grid_points[i,0], grid_points[i,1]]\n",
    "                v10_sum = v10_sum + v10_point\n",
    "                \n",
    "                # Computation for 10-m wind speed\n",
    "                uv10_point = wind_speed(u10_point, v10_point)\n",
    "                uv10_sum = uv10_sum + uv10_point\n",
    "                \n",
    "                # Computation for lifted condensation level pressure\n",
    "                dew_point = dewpoint_from_relative_humidity(((t2m_point - 273.15) * units('degC')), rh2m_point)\n",
    "                lcl_point = lcl(((slp_point / 100)  * units('hPa')), t2m_point, dew_point)\n",
    "                lcl_sum = lcl_sum + lcl_point[0]\n",
    "                \n",
    "                # Computation for 0-6 km shear\n",
    "                u_shear_0_6_point = (ds_raw.get('VUCSH_P0_2L103_GLC0')[grid_points[i,0], grid_points[i,1]]) * units('m/s')\n",
    "                v_shear_0_6_point = (ds_raw.get('VVCSH_P0_2L103_GLC0')[grid_points[i,0], grid_points[i,1]]) * units('m/s')\n",
    "                shear_0_6_point = wind_speed(u_shear_0_6_point, v_shear_0_6_point)\n",
    "                shear_0_6_sum = shear_0_6_sum + shear_0_6_point\n",
    "                \n",
    "                # 0-1 km storm relative helicity\n",
    "                srh_0_1_point = ds_raw.get('HLCY_P0_2L103_GLC0')[0][grid_points[i,0], grid_points[i,1]]\n",
    "                srh_0_1_sum = srh_0_1_sum + srh_0_1_point\n",
    "                \n",
    "                # 0-3 km storm relative helicity\n",
    "                srh_0_3_point = ds_raw.get('HLCY_P0_2L103_GLC0')[1][grid_points[i,0], grid_points[i,1]]\n",
    "                srh_0_3_sum = srh_0_3_sum + srh_0_3_point\n",
    "                \n",
    "                # Increase number of points with minimal reflectivity by 1\n",
    "                number_points += 1\n",
    "                \n",
    "        # Calculate average over number of grid points and round output\n",
    "        pwat_avg = float(np.round((pwat_sum / number_points), 4)) # kg/m^2\n",
    "        mslp_avg = float(np.round(((mslp_sum / number_points) / 100), 4)) # hPa\n",
    "        cape_avg = float(np.round((cape_sum / number_points), 4)) # J/kg\n",
    "        cin_avg = float(np.round((cin_sum / number_points), 4)) # J/kg\n",
    "        t2m_avg = float(np.round(((t2m_sum / number_points) - 273.15), 4)) # deg C\n",
    "        rh2m_avg = float(np.round((rh2m_sum / number_points), 4)) # percent\n",
    "        q2m_avg = float(np.round(((q2m_sum / number_points) * 1000), 4)) # g/kg\n",
    "        u10_avg = float(np.round((u10_sum / number_points), 4)) # m/s\n",
    "        v10_avg = float(np.round((v10_sum / number_points), 4)) # m/s\n",
    "        uv10_avg = float(np.round((uv10_sum / number_points), 4)) # m/s\n",
    "        lcl_avg = np.round(((lcl_sum.magnitude) / number_points), 4) # hPa\n",
    "        shr0_6_avg = float(np.round((shear_0_6_sum / number_points), 4)) # 1/s\n",
    "        srh0_1_avg = float(np.round((srh_0_1_sum / number_points), 4)) # m^2/s^2\n",
    "        srh0_3_avg = float(np.round((srh_0_3_sum / number_points), 4)) # m^2/s^2\n",
    "        \n",
    "        # Set time variables equal to ints\n",
    "        year = int(year)\n",
    "        month = int(month)\n",
    "        day = int(day)\n",
    "        hour = int(hour)\n",
    "            \n",
    "        # Export outputs into a csv filter\n",
    "        data = [year, month, day, hour, label, pwat_avg, mslp_avg, cape_avg, cin_avg, t2m_avg, rh2m_avg, q2m_avg, u10_avg, v10_avg,\n",
    "                uv10_avg, lcl_avg, shr0_6_avg, srh0_1_avg, srh0_3_avg]\n",
    "        \n",
    "        with open(\"central_ok_mds_env_FINAL.csv\", 'a', newline='') as output_file:\n",
    "            output_writer = writer(output_file)\n",
    "            output_writer.writerow(data)\n",
    "            output_file.close()\n",
    "        \n",
    "        input_csv_row += 1\n",
    "    \n",
    "    # Input MD data so manual inspection of RAP analysis can be done\n",
    "    # Files can be found at https://www.ncei.noaa.gov/products/weather-climate-models/rapid-refresh-update\n",
    "    else:\n",
    "        year = int(year)\n",
    "        month = int(month)\n",
    "        day = int(day)\n",
    "        hour = int(hour)\n",
    "        \n",
    "        data = [year, month, day, hour, label, placeholder, placeholder, placeholder, placeholder, placeholder, placeholder, placeholder, \n",
    "                placeholder, placeholder, placeholder, placeholder, placeholder, placeholder, placeholder]\n",
    "        \n",
    "        # Export outputs into a csv filter\n",
    "        with open(\"central_ok_mds_env_FINAL.csv\", 'a', newline='') as output_file:\n",
    "            output_writer = writer(output_file)\n",
    "            output_writer.writerow(data)\n",
    "            output_file.close()\n",
    "            \n",
    "        input_csv_row += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyEAE]",
   "language": "python",
   "name": "conda-env-pyEAE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
